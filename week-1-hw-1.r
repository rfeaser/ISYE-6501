{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a24c147",
   "metadata": {
    "papermill": {
     "duration": 0.006545,
     "end_time": "2022-07-08T13:58:39.501727",
     "exception": false,
     "start_time": "2022-07-08T13:58:39.495182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a806f98",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-21T21:53:14.982147Z",
     "iopub.status.busy": "2022-05-21T21:53:14.979902Z",
     "iopub.status.idle": "2022-05-21T21:53:15.11148Z"
    },
    "papermill": {
     "duration": 0.005607,
     "end_time": "2022-07-08T13:58:39.513770",
     "exception": false,
     "start_time": "2022-07-08T13:58:39.508163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question 2.1\n",
    "I am currently employed in the supply chain industry, and my employer recentaly committed to net-zero carbon emissions across all areas of our business by 2040. Considering the size and complexty of our distribution network, this is not going to be an easy feat as about half of our carbon emissions come from energy consumption, a third from refrigeration systems, and about ten percent from transportation. Thus, we are currently working to classify each area of our operations as sustainable/unsustainable based on industry averages. Some of the factors we are using to predict whether a warehouse/operational building is considered sustainable at include electricity consumption, renewable energy production, natural gas/water/fuel consumption, trash waste, cardboard/plastic/metal recycling, and ozone depletion (charges vs leakage for a number of refrigerants) to name a few."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ddef4a",
   "metadata": {
    "papermill": {
     "duration": 0.00652,
     "end_time": "2022-07-08T13:58:39.525671",
     "exception": false,
     "start_time": "2022-07-08T13:58:39.519151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question 2.2.1\n",
    "Using the support vector machine function ksvm contained in the R package kernlab, find a good classifier for this data. Show the equation of your classifier, and how well it classifies the data points in the full data set. (Don’t worry about test/validation data yet; we’ll cover that topic soon.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43c9db9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T13:58:39.542911Z",
     "iopub.status.busy": "2022-07-08T13:58:39.540056Z",
     "iopub.status.idle": "2022-07-08T13:58:40.440534Z",
     "shell.execute_reply": "2022-07-08T13:58:40.438022Z"
    },
    "papermill": {
     "duration": 0.911488,
     "end_time": "2022-07-08T13:58:40.443502",
     "exception": false,
     "start_time": "2022-07-08T13:58:39.532014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  A1    A2    A3   A8 A9 A10 A11 A12 A14 A15 R1\n",
      "1  1 30.83 0.000 1.25  1   0   1   1 202   0  1\n",
      "2  0 58.67 4.460 3.04  1   0   6   1  43 560  1\n",
      "3  0 24.50 0.500 1.50  1   1   0   1 280 824  1\n",
      "4  1 27.83 1.540 3.75  1   0   5   0 100   3  1\n",
      "5  1 20.17 5.625 1.71  1   1   0   1 120   0  1\n",
      "6  1 32.08 4.000 2.50  1   1   0   0 360   0  1\n",
      "    A1    A2     A3   A8 A9 A10 A11 A12 A14 A15 R1\n",
      "649  1 40.58  3.290 3.50  0   1   0   0 400   0  0\n",
      "650  1 21.08 10.085 1.25  0   1   0   1 260   0  0\n",
      "651  0 22.67  0.750 2.00  0   0   2   0 200 394  0\n",
      "652  0 25.25 13.500 2.00  0   0   1   0 200   1  0\n",
      "653  1 17.92  0.205 0.04  0   1   0   1 280 750  0\n",
      "654  1 35.00  3.375 8.29  0   1   0   0   0   0  0\n",
      "       A1               A2              A3               A8        \n",
      " Min.   :0.0000   Min.   :13.75   Min.   : 0.000   Min.   : 0.000  \n",
      " 1st Qu.:0.0000   1st Qu.:22.58   1st Qu.: 1.040   1st Qu.: 0.165  \n",
      " Median :1.0000   Median :28.46   Median : 2.855   Median : 1.000  \n",
      " Mean   :0.6896   Mean   :31.58   Mean   : 4.831   Mean   : 2.242  \n",
      " 3rd Qu.:1.0000   3rd Qu.:38.25   3rd Qu.: 7.438   3rd Qu.: 2.615  \n",
      " Max.   :1.0000   Max.   :80.25   Max.   :28.000   Max.   :28.500  \n",
      "       A9              A10              A11              A12        \n",
      " Min.   :0.0000   Min.   :0.0000   Min.   : 0.000   Min.   :0.0000  \n",
      " 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.:0.0000  \n",
      " Median :1.0000   Median :1.0000   Median : 0.000   Median :1.0000  \n",
      " Mean   :0.5352   Mean   :0.5612   Mean   : 2.498   Mean   :0.5382  \n",
      " 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.: 3.000   3rd Qu.:1.0000  \n",
      " Max.   :1.0000   Max.   :1.0000   Max.   :67.000   Max.   :1.0000  \n",
      "      A14               A15               R1        \n",
      " Min.   :   0.00   Min.   :     0   Min.   :0.0000  \n",
      " 1st Qu.:  70.75   1st Qu.:     0   1st Qu.:0.0000  \n",
      " Median : 160.00   Median :     5   Median :0.0000  \n",
      " Mean   : 180.08   Mean   :  1013   Mean   :0.4526  \n",
      " 3rd Qu.: 271.00   3rd Qu.:   399   3rd Qu.:1.0000  \n",
      " Max.   :2000.00   Max.   :100000   Max.   :1.0000  \n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"kernlab\")\n",
    "library(kernlab)\n",
    "rm(list = ls())\n",
    "set.seed(1)\n",
    "\n",
    "#Loading the data into a table\n",
    "cc_data <- read.table(\"../input/week-1-homework/week 1 data-summer/data 2.2/credit_card_data-headers.txt\", header = TRUE, sep = \"\")\n",
    "\n",
    "#Exploring and verifying the data\n",
    "print(head(cc_data))\n",
    "print(tail(cc_data))\n",
    "print(summary(cc_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a402fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T13:58:40.489848Z",
     "iopub.status.busy": "2022-07-08T13:58:40.456477Z",
     "iopub.status.idle": "2022-07-08T13:58:45.581965Z",
     "shell.execute_reply": "2022-07-08T13:58:45.579301Z"
    },
    "papermill": {
     "duration": 5.136009,
     "end_time": "2022-07-08T13:58:45.585183",
     "exception": false,
     "start_time": "2022-07-08T13:58:40.449174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      "Support Vector Machine object of class \"ksvm\" \n",
      "\n",
      "SV type: C-svc  (classification) \n",
      " parameter : cost C = 129 \n",
      "\n",
      "Linear (vanilla) kernel function. \n",
      "\n",
      "Number of Support Vectors : 192 \n",
      "\n",
      "Objective Function Value : -23075.33 \n",
      "Training error : 0.136086 \n"
     ]
    }
   ],
   "source": [
    "#Creating my kvsm model (part of kernlab package). Vanilladot is a simple linear kernerl.\n",
    "model<- ksvm(R1~.,\n",
    "              data = cc_data,\n",
    "              type = \"C-svc\", \n",
    "              kernel = \"vanilladot\", \n",
    "              C = 129, scale = TRUE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bc9efe",
   "metadata": {
    "papermill": {
     "duration": 0.007295,
     "end_time": "2022-07-08T13:58:45.598414",
     "exception": false,
     "start_time": "2022-07-08T13:58:45.591119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I estimated values of C and found that for values ranging from 1 to 258 the training error values do not hange significantly, but as C beings to increase beyond 258, the training error also begins to increase. Thus, my classifier C is 129 (splitting the difference between 1 and 258) to avoid maximizing/minimizing the margin too greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aac8327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T13:58:45.613704Z",
     "iopub.status.busy": "2022-07-08T13:58:45.612116Z",
     "iopub.status.idle": "2022-07-08T13:58:45.634113Z",
     "shell.execute_reply": "2022-07-08T13:58:45.632273Z"
    },
    "papermill": {
     "duration": 0.032455,
     "end_time": "2022-07-08T13:58:45.637095",
     "exception": false,
     "start_time": "2022-07-08T13:58:45.604640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>A1</dt><dd>-0.00102950341757152</dd><dt>A2</dt><dd>-0.000974773459803735</dd><dt>A3</dt><dd>-0.00157931936844014</dd><dt>A8</dt><dd>0.00295425557098525</dd><dt>A9</dt><dd>1.00474474526717</dd><dt>A10</dt><dd>-0.00293191563800471</dd><dt>A11</dt><dd>-0.000205207985110201</dd><dt>A12</dt><dd>-0.000614396058832789</dd><dt>A14</dt><dd>-0.00140826472042958</dd><dt>A15</dt><dd>0.106362988559465</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[A1] -0.00102950341757152\n",
       "\\item[A2] -0.000974773459803735\n",
       "\\item[A3] -0.00157931936844014\n",
       "\\item[A8] 0.00295425557098525\n",
       "\\item[A9] 1.00474474526717\n",
       "\\item[A10] -0.00293191563800471\n",
       "\\item[A11] -0.000205207985110201\n",
       "\\item[A12] -0.000614396058832789\n",
       "\\item[A14] -0.00140826472042958\n",
       "\\item[A15] 0.106362988559465\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "A1\n",
       ":   -0.00102950341757152A2\n",
       ":   -0.000974773459803735A3\n",
       ":   -0.00157931936844014A8\n",
       ":   0.00295425557098525A9\n",
       ":   1.00474474526717A10\n",
       ":   -0.00293191563800471A11\n",
       ":   -0.000205207985110201A12\n",
       ":   -0.000614396058832789A14\n",
       ":   -0.00140826472042958A15\n",
       ":   0.106362988559465\n",
       "\n"
      ],
      "text/plain": [
       "           A1            A2            A3            A8            A9 \n",
       "-0.0010295034 -0.0009747735 -0.0015793194  0.0029542556  1.0047447453 \n",
       "          A10           A11           A12           A14           A15 \n",
       "-0.0029319156 -0.0002052080 -0.0006143961 -0.0014082647  0.1063629886 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate a1…am\n",
    "a <- colSums(model@xmatrix[[1]] * model@coef[[1]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af259dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T13:58:45.653263Z",
     "iopub.status.busy": "2022-07-08T13:58:45.651549Z",
     "iopub.status.idle": "2022-07-08T13:58:45.671751Z",
     "shell.execute_reply": "2022-07-08T13:58:45.669960Z"
    },
    "papermill": {
     "duration": 0.030976,
     "end_time": "2022-07-08T13:58:45.674170",
     "exception": false,
     "start_time": "2022-07-08T13:58:45.643194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0816458067092025"
      ],
      "text/latex": [
       "0.0816458067092025"
      ],
      "text/markdown": [
       "0.0816458067092025"
      ],
      "text/plain": [
       "[1] 0.08164581"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate a0\n",
    "a0 <- -model@b\n",
    "a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e36cd3ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T13:58:45.689739Z",
     "iopub.status.busy": "2022-07-08T13:58:45.688125Z",
     "iopub.status.idle": "2022-07-08T13:58:45.974792Z",
     "shell.execute_reply": "2022-07-08T13:58:45.971889Z"
    },
    "papermill": {
     "duration": 0.297731,
     "end_time": "2022-07-08T13:58:45.977910",
     "exception": false,
     "start_time": "2022-07-08T13:58:45.680179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>⋯</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item ⋯\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 1\n",
       "3. 1\n",
       "4. 1\n",
       "5. 1\n",
       "6. 1\n",
       "7. 1\n",
       "8. 1\n",
       "9. 1\n",
       "10. 1\n",
       "11. 0\n",
       "12. 1\n",
       "13. 1\n",
       "14. 0\n",
       "15. 1\n",
       "16. 1\n",
       "17. 1\n",
       "18. 1\n",
       "19. 1\n",
       "20. 1\n",
       "21. 1\n",
       "22. 1\n",
       "23. 1\n",
       "24. 1\n",
       "25. 1\n",
       "26. 1\n",
       "27. 1\n",
       "28. 1\n",
       "29. 1\n",
       "30. 1\n",
       "31. 1\n",
       "32. 1\n",
       "33. 1\n",
       "34. 1\n",
       "35. 1\n",
       "36. 1\n",
       "37. 1\n",
       "38. 1\n",
       "39. 1\n",
       "40. 1\n",
       "41. 1\n",
       "42. 1\n",
       "43. 1\n",
       "44. 1\n",
       "45. 1\n",
       "46. 1\n",
       "47. 1\n",
       "48. 1\n",
       "49. 0\n",
       "50. 0\n",
       "51. 1\n",
       "52. 1\n",
       "53. 1\n",
       "54. 1\n",
       "55. 1\n",
       "56. 1\n",
       "57. 1\n",
       "58. 1\n",
       "59. 0\n",
       "60. 1\n",
       "61. 1\n",
       "62. 1\n",
       "63. 1\n",
       "64. 1\n",
       "65. 1\n",
       "66. 1\n",
       "67. 1\n",
       "68. 1\n",
       "69. 1\n",
       "70. 1\n",
       "71. 1\n",
       "72. 1\n",
       "73. 1\n",
       "74. 0\n",
       "75. 1\n",
       "76. 1\n",
       "77. 1\n",
       "78. 1\n",
       "79. 1\n",
       "80. 1\n",
       "81. 1\n",
       "82. 1\n",
       "83. 1\n",
       "84. 1\n",
       "85. 1\n",
       "86. 1\n",
       "87. 1\n",
       "88. 1\n",
       "89. 1\n",
       "90. 1\n",
       "91. 1\n",
       "92. 1\n",
       "93. 1\n",
       "94. 1\n",
       "95. 1\n",
       "96. 1\n",
       "97. 1\n",
       "98. 1\n",
       "99. 1\n",
       "100. 1\n",
       "101. 1\n",
       "102. 1\n",
       "103. 1\n",
       "104. 1\n",
       "105. 1\n",
       "106. 1\n",
       "107. 1\n",
       "108. 1\n",
       "109. 1\n",
       "110. 1\n",
       "111. 1\n",
       "112. 1\n",
       "113. 1\n",
       "114. 1\n",
       "115. 1\n",
       "116. 1\n",
       "117. 1\n",
       "118. 1\n",
       "119. 1\n",
       "120. 1\n",
       "121. 1\n",
       "122. 1\n",
       "123. 1\n",
       "124. 1\n",
       "125. 1\n",
       "126. 1\n",
       "127. 1\n",
       "128. 1\n",
       "129. 1\n",
       "130. 1\n",
       "131. 1\n",
       "132. 1\n",
       "133. 1\n",
       "134. 1\n",
       "135. 1\n",
       "136. 1\n",
       "137. 1\n",
       "138. 1\n",
       "139. 1\n",
       "140. 1\n",
       "141. 1\n",
       "142. 1\n",
       "143. 1\n",
       "144. 1\n",
       "145. 1\n",
       "146. 1\n",
       "147. 1\n",
       "148. 1\n",
       "149. 1\n",
       "150. 1\n",
       "151. 1\n",
       "152. 1\n",
       "153. 1\n",
       "154. 1\n",
       "155. 1\n",
       "156. 1\n",
       "157. 1\n",
       "158. 1\n",
       "159. 1\n",
       "160. 1\n",
       "161. 1\n",
       "162. 1\n",
       "163. 1\n",
       "164. 1\n",
       "165. 0\n",
       "166. 1\n",
       "167. 1\n",
       "168. 1\n",
       "169. 1\n",
       "170. 1\n",
       "171. 1\n",
       "172. 1\n",
       "173. 1\n",
       "174. 1\n",
       "175. 1\n",
       "176. 1\n",
       "177. 1\n",
       "178. 1\n",
       "179. 1\n",
       "180. 1\n",
       "181. 1\n",
       "182. 1\n",
       "183. 1\n",
       "184. 1\n",
       "185. 1\n",
       "186. 1\n",
       "187. 1\n",
       "188. 1\n",
       "189. 1\n",
       "190. 1\n",
       "191. 1\n",
       "192. 1\n",
       "193. 1\n",
       "194. 1\n",
       "195. 1\n",
       "196. 1\n",
       "197. 1\n",
       "198. 1\n",
       "199. 1\n",
       "200. 1\n",
       "201. ⋯\n",
       "202. 0\n",
       "203. 0\n",
       "204. 0\n",
       "205. 0\n",
       "206. 0\n",
       "207. 0\n",
       "208. 0\n",
       "209. 0\n",
       "210. 0\n",
       "211. 0\n",
       "212. 0\n",
       "213. 1\n",
       "214. 1\n",
       "215. 1\n",
       "216. 1\n",
       "217. 1\n",
       "218. 1\n",
       "219. 1\n",
       "220. 1\n",
       "221. 1\n",
       "222. 1\n",
       "223. 1\n",
       "224. 1\n",
       "225. 1\n",
       "226. 1\n",
       "227. 1\n",
       "228. 1\n",
       "229. 1\n",
       "230. 1\n",
       "231. 1\n",
       "232. 1\n",
       "233. 1\n",
       "234. 1\n",
       "235. 1\n",
       "236. 1\n",
       "237. 1\n",
       "238. 1\n",
       "239. 1\n",
       "240. 1\n",
       "241. 1\n",
       "242. 1\n",
       "243. 1\n",
       "244. 1\n",
       "245. 1\n",
       "246. 1\n",
       "247. 1\n",
       "248. 1\n",
       "249. 1\n",
       "250. 1\n",
       "251. 1\n",
       "252. 1\n",
       "253. 1\n",
       "254. 1\n",
       "255. 1\n",
       "256. 1\n",
       "257. 1\n",
       "258. 1\n",
       "259. 1\n",
       "260. 1\n",
       "261. 1\n",
       "262. 1\n",
       "263. 1\n",
       "264. 1\n",
       "265. 1\n",
       "266. 1\n",
       "267. 1\n",
       "268. 1\n",
       "269. 1\n",
       "270. 1\n",
       "271. 1\n",
       "272. 1\n",
       "273. 1\n",
       "274. 1\n",
       "275. 1\n",
       "276. 1\n",
       "277. 1\n",
       "278. 1\n",
       "279. 1\n",
       "280. 1\n",
       "281. 1\n",
       "282. 1\n",
       "283. 1\n",
       "284. 1\n",
       "285. 1\n",
       "286. 1\n",
       "287. 1\n",
       "288. 1\n",
       "289. 1\n",
       "290. 1\n",
       "291. 1\n",
       "292. 1\n",
       "293. 1\n",
       "294. 1\n",
       "295. 1\n",
       "296. 1\n",
       "297. 1\n",
       "298. 1\n",
       "299. 1\n",
       "300. 1\n",
       "301. 0\n",
       "302. 1\n",
       "303. 1\n",
       "304. 1\n",
       "305. 1\n",
       "306. 1\n",
       "307. 1\n",
       "308. 1\n",
       "309. 1\n",
       "310. 1\n",
       "311. 1\n",
       "312. 0\n",
       "313. 1\n",
       "314. 1\n",
       "315. 1\n",
       "316. 1\n",
       "317. 1\n",
       "318. 1\n",
       "319. 0\n",
       "320. 0\n",
       "321. 1\n",
       "322. 0\n",
       "323. 0\n",
       "324. 0\n",
       "325. 0\n",
       "326. 0\n",
       "327. 0\n",
       "328. 0\n",
       "329. 0\n",
       "330. 0\n",
       "331. 0\n",
       "332. 0\n",
       "333. 0\n",
       "334. 0\n",
       "335. 1\n",
       "336. 0\n",
       "337. 0\n",
       "338. 0\n",
       "339. 0\n",
       "340. 0\n",
       "341. 0\n",
       "342. 0\n",
       "343. 0\n",
       "344. 0\n",
       "345. 0\n",
       "346. 0\n",
       "347. 0\n",
       "348. 0\n",
       "349. 0\n",
       "350. 0\n",
       "351. 0\n",
       "352. 0\n",
       "353. 0\n",
       "354. 0\n",
       "355. 0\n",
       "356. 0\n",
       "357. 0\n",
       "358. 0\n",
       "359. 0\n",
       "360. 0\n",
       "361. 0\n",
       "362. 0\n",
       "363. 0\n",
       "364. 0\n",
       "365. 0\n",
       "366. 1\n",
       "367. 0\n",
       "368. 0\n",
       "369. 0\n",
       "370. 0\n",
       "371. 0\n",
       "372. 0\n",
       "373. 0\n",
       "374. 0\n",
       "375. 0\n",
       "376. 0\n",
       "377. 0\n",
       "378. 0\n",
       "379. 0\n",
       "380. 0\n",
       "381. 0\n",
       "382. 0\n",
       "383. 0\n",
       "384. 0\n",
       "385. 0\n",
       "386. 0\n",
       "387. 0\n",
       "388. 0\n",
       "389. 0\n",
       "390. 0\n",
       "391. 0\n",
       "392. 0\n",
       "393. 0\n",
       "394. 0\n",
       "395. 0\n",
       "396. 0\n",
       "397. 0\n",
       "398. 0\n",
       "399. 0\n",
       "400. 0\n",
       "401. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " [38] 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
       " [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       "[112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       "[149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       "[186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
       "[223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       "[260] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       "[297] 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       "[334] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[371] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[408] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[445] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       "[482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       "[519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
       "[556] 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       "[593] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       "[630] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see what the model predicts\n",
    "pred <- predict(model, as.matrix(cc_data[,1:10]))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "844c8c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T13:58:46.012618Z",
     "iopub.status.busy": "2022-07-08T13:58:45.995320Z",
     "iopub.status.idle": "2022-07-08T13:58:46.034457Z",
     "shell.execute_reply": "2022-07-08T13:58:46.032544Z"
    },
    "papermill": {
     "duration": 0.052255,
     "end_time": "2022-07-08T13:58:46.037290",
     "exception": false,
     "start_time": "2022-07-08T13:58:45.985035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.863914373088685"
      ],
      "text/latex": [
       "0.863914373088685"
      ],
      "text/markdown": [
       "0.863914373088685"
      ],
      "text/plain": [
       "[1] 0.8639144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see what fraction of the model’s predictions match the actual classification\n",
    "sum(pred == as.factor(cc_data[,11])) / nrow(cc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921940a",
   "metadata": {
    "papermill": {
     "duration": 0.007752,
     "end_time": "2022-07-08T13:58:46.052640",
     "exception": false,
     "start_time": "2022-07-08T13:58:46.044888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Thus, the classifier's equation is the following: -0.00102950341757152(A1) + -0.000974773459803735(A2) + -0.00157931936844014(A3) + 0.00295425557098525(A8) + 1.00474474526717(A9)+ -0.00293191563800471(A10) + -0.000205207985110201(A11) + -0.000614396058832789(A12) + -0.00140826472042958(A14) + 0.106362988559465(A15) +  0.0816458067092025 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678987e6",
   "metadata": {
    "papermill": {
     "duration": 0.007699,
     "end_time": "2022-07-08T13:58:46.067899",
     "exception": false,
     "start_time": "2022-07-08T13:58:46.060200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question 2.2.3\n",
    "Using the k-nearest-neighbors classification function kknn contained in the R kknn package, suggest a good value of k, and show how well it classifies that data points in the full data set. Don’t forget to scale the data (scale=TRUE in kknn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7033368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T13:58:46.086930Z",
     "iopub.status.busy": "2022-07-08T13:58:46.085226Z",
     "iopub.status.idle": "2022-07-08T13:59:42.201993Z",
     "shell.execute_reply": "2022-07-08T13:59:42.200269Z"
    },
    "papermill": {
     "duration": 56.135452,
     "end_time": "2022-07-08T13:59:42.211358",
     "exception": false,
     "start_time": "2022-07-08T13:58:46.075906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           [,1]\n",
      " [1,] 0.8149847\n",
      " [2,] 0.8149847\n",
      " [3,] 0.8149847\n",
      " [4,] 0.8149847\n",
      " [5,] 0.8516820\n",
      " [6,] 0.8455657\n",
      " [7,] 0.8470948\n",
      " [8,] 0.8486239\n",
      " [9,] 0.8470948\n",
      "[10,] 0.8501529\n",
      "[11,] 0.8516820\n",
      "[12,] 0.8532110\n",
      "[13,] 0.8516820\n",
      "[14,] 0.8516820\n",
      "[15,] 0.8532110\n",
      "[16,] 0.8516820\n",
      "[17,] 0.8516820\n",
      "[18,] 0.8516820\n",
      "[19,] 0.8501529\n",
      "[20,] 0.8501529\n"
     ]
    }
   ],
   "source": [
    "#First we'll load in the kknn package that we will use to build our model. Then we'll create a for loop to test and store the accuracy of several different values of k to determine which performs best using leave-one-out cross validation (manually).\n",
    "library(kknn)\n",
    "set.seed(2)\n",
    "\n",
    "#Creating a vector of zeroes for as many rows are in the dataset to store the model's response variables\n",
    "predictions = rep(0,(nrow(cc_data)))\n",
    "\n",
    "#Creating a vector of 10 zeroes to use as k_values in a loop to determine which seems like the best option for our model\n",
    "k_values = rep(0, 20)\n",
    "\n",
    "#Loop through the number of k values I want to test to determine which is best for our model\n",
    "for (j in 1:20) {\n",
    "    for (i in 1:nrow(cc_data)) {\n",
    "        model <- kknn(R1~., cc_data[-i,], cc_data[i,], k = j, scale = TRUE)\n",
    "        #Storing the reponse variable of the model in our predictions but rounded since kknn reads responses as continuous and returns the fraction of the k closest responses that are 1\n",
    "        predictions[i] <- round(as.numeric(fitted(model)))\n",
    "    }\n",
    "    #Tests how accurate the model at the specified iteration of k in the first for loop\n",
    "    k_values[j] = sum(predictions == cc_data[,11])/nrow(cc_data)\n",
    "}\n",
    "\n",
    "#printing out accuracy of each k_value so we can see which values work best for our model\n",
    "print(as.matrix(k_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe47a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T01:40:15.439079Z",
     "iopub.status.busy": "2022-05-23T01:40:15.437483Z",
     "iopub.status.idle": "2022-05-23T01:40:15.476343Z"
    },
    "papermill": {
     "duration": 0.00722,
     "end_time": "2022-07-08T13:59:42.225682",
     "exception": false,
     "start_time": "2022-07-08T13:59:42.218462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see from above looping through possible k values ranging from 1 to 10, our model operates best when k is set to 12 or 15 (both have the highest accuracy of our 20 options with ~85.32% correctly predicted responses), but we could improve upon this by increasing our for loop beyond 20 to test greater values of k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587f453",
   "metadata": {
    "papermill": {
     "duration": 0.006984,
     "end_time": "2022-07-08T13:59:42.239731",
     "exception": false,
     "start_time": "2022-07-08T13:59:42.232747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question 3.1\n",
    "\n",
    "Using the same data set (credit_card_data.txt or credit_card_data-headers.txt) as in Question 2.2, use the ksvm or kknn function to find a good classifier:\n",
    "(a) using cross-validation (do this for the k-nearest-neighbors model; SVM is optional); and\n",
    "(b) splitting the data into training, validation, and test data sets (pick either KNN or SVM; the other is optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9dd45ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T13:59:42.257543Z",
     "iopub.status.busy": "2022-07-08T13:59:42.256000Z",
     "iopub.status.idle": "2022-07-08T13:59:42.553188Z",
     "shell.execute_reply": "2022-07-08T13:59:42.551489Z"
    },
    "papermill": {
     "duration": 0.308602,
     "end_time": "2022-07-08T13:59:42.555509",
     "exception": false,
     "start_time": "2022-07-08T13:59:42.246907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "train.kknn(formula = R1 ~ ., data = cc_data, kmax = 100, scale = TRUE)\n",
       "\n",
       "Type of response variable: continuous\n",
       "minimal mean absolute error: 0.1850153\n",
       "Minimal mean squared error: 0.1073792\n",
       "Best kernel: optimal\n",
       "Best k: 58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#(A) Cross-validation (k-fold cross validation). First we'll split out dataset into training and testing sets and then train the kknn method via leave-one-out like in exercise 2.3)\n",
    "set.seed(3)\n",
    "#Generate a random sample of 70% of the rows\n",
    "random <- sample(1:nrow(cc_data),as.integer(0.7*nrow(cc_data)))\n",
    "\n",
    "#Creating a training set with 70% of the original data set.  \n",
    "train = cc_data[random,]\n",
    "\n",
    "#Creating a test set with 30% of the original data set. \n",
    "test = cc_data[-random,]\n",
    "\n",
    "#Training of kknn method via leave-one-out (train.kknn) K-fold cross validation which sets K equal to the number of data points in the set which means that the function is trained as many times as there are data points in the set for all data except for one point and a prediction is made for that point.\n",
    "train.kknn(R1~., cc_data, kmax = 100, scale = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c181f35",
   "metadata": {
    "papermill": {
     "duration": 0.007946,
     "end_time": "2022-07-08T13:59:42.571091",
     "exception": false,
     "start_time": "2022-07-08T13:59:42.563145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see above, our model apppears to work best when k is set to 11. Let's further check this by running our model on the training and test sets and calculating their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "566b5b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T13:59:42.589866Z",
     "iopub.status.busy": "2022-07-08T13:59:42.588171Z",
     "iopub.status.idle": "2022-07-08T13:59:45.106282Z",
     "shell.execute_reply": "2022-07-08T13:59:45.104062Z"
    },
    "papermill": {
     "duration": 2.530729,
     "end_time": "2022-07-08T13:59:45.109444",
     "exception": false,
     "start_time": "2022-07-08T13:59:42.578715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Train Accuracy:  0.824945295404814\"\n",
      "[1] \"Test Accuracy:  0.83756345177665\"\n"
     ]
    }
   ],
   "source": [
    "#Here we will determine how accurate our model is using the k-value suggested in cross-validation (essentially a repeat of question 2.3).\n",
    "\n",
    "# Calculating accuracy on the train data set\n",
    "pr_train <- rep(0,(nrow(train))) # predictions: start with a vector of all zeros\n",
    "train_accuracy<- rep(0,(nrow(train)))  #initialize variable\n",
    "\n",
    "for (i in 1:nrow(train)){\n",
    "  model <- kknn(R1~.,train[-i,],train[i,],k=58,kernel=\"optimal\", scale = TRUE)\n",
    "  pr_train[i]<- round(as.numeric(fitted(model))) \n",
    "}\n",
    "     \n",
    "train_accuracy<- sum(pr_train == train[,11])/nrow(train)\n",
    "\n",
    "# Calculating accuracy on the test data set\n",
    "\n",
    "pr_test <- rep(0,(nrow(test))) # predictions: start with a vector of all zeros\n",
    "test_accuracy<- 0 #initialize variable\n",
    "\n",
    "for (i in 1:nrow(test)){\n",
    "  model=kknn(R1~.,test[-i,],test[i,],k=58,kernel=\"optimal\", scale = TRUE) # use scaled data\n",
    "  pr_test[i]<- round(as.numeric(fitted(model)))\n",
    "}\n",
    "\n",
    "# calculate fraction of correct predictions\n",
    "test_accuracy<- sum(pr_test == test[,11]) / nrow(test)\n",
    "\n",
    "#printed comparison of the model's accuracy on the test and training data\n",
    "print(paste(\"Train Accuracy: \", train_accuracy))\n",
    "print(paste(\"Test Accuracy: \", test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3810b865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T13:59:45.128453Z",
     "iopub.status.busy": "2022-07-08T13:59:45.126933Z",
     "iopub.status.idle": "2022-07-08T14:00:09.464015Z",
     "shell.execute_reply": "2022-07-08T14:00:09.462152Z"
    },
    "papermill": {
     "duration": 24.350136,
     "end_time": "2022-07-08T14:00:09.467345",
     "exception": false,
     "start_time": "2022-07-08T13:59:45.117209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      "Best SVM model number=  3 \n",
      "Best C value = 0.01 \n",
      "Best training set model accuracy (%)= 85.55799"
     ]
    }
   ],
   "source": [
    "#(B) splitting data into training, validation, and test data sets and testing the SVM\n",
    "set.seed(5)\n",
    "\n",
    "#Generate a random sample of 70% of the rows\n",
    "random <- sample(1:nrow(cc_data),as.integer(0.7*nrow(cc_data)))\n",
    "\n",
    "#Creating a training set with 70% of the original data set. \n",
    "cc_train = cc_data[random,]\n",
    "\n",
    "#Create a set to store the remaining 30% of the original set that we'll split into validation and test sets\n",
    "leftover = cc_data[-random,]\n",
    "\n",
    "# Split the remaining data into a validation set and test set\n",
    "validation = sample(nrow(leftover), size = floor(nrow(leftover)/2))\n",
    "\n",
    "# validation data set\n",
    "cc_validation = leftover[validation,] \n",
    "\n",
    "# test data set\n",
    "cc_test = leftover[-validation,] \n",
    "\n",
    "TVT_accuracy = rep(0,9)  # 1-9 are SVM, 10-29 are KNN\n",
    "\n",
    "# We have to Train SVM models\n",
    "# values of C to test\n",
    "\n",
    "c_values = c(0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000) \n",
    "\n",
    "for (i in 1:9) {\n",
    "  \n",
    "#fitting the model using the training dataset and C-classification method with vanilladot\n",
    "  \n",
    "ccmodel <- ksvm(as.matrix(cc_train[,1:10]),\n",
    "                as.factor(cc_train[,11]), \n",
    "                type = \"C-svc\",kernel = \"vanilladot\",C = c_values[i],scaled=TRUE) \n",
    "  \n",
    "#Model's prediction on validation dataset\n",
    "    pred = predict(ccmodel,cc_train[,1:10])\n",
    "    \n",
    "#Calculating model's prediction accuracy`on validation dataset\n",
    "  TVT_accuracy[i] = (sum(pred == cc_train$R1) / nrow(cc_train))*100\n",
    "}\n",
    "\n",
    "cat(\"Best SVM model number= \",which.max(TVT_accuracy), \"\\n\")\n",
    "cat(\"Best C value =\",c_values[which.max(TVT_accuracy)], \"\\n\")\n",
    "cat(\"Best training set model accuracy (%)=\",max(TVT_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ffb6200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T14:00:09.487381Z",
     "iopub.status.busy": "2022-07-08T14:00:09.485754Z",
     "iopub.status.idle": "2022-07-08T14:00:09.521734Z",
     "shell.execute_reply": "2022-07-08T14:00:09.519915Z"
    },
    "papermill": {
     "duration": 0.048195,
     "end_time": "2022-07-08T14:00:09.524216",
     "exception": false,
     "start_time": "2022-07-08T14:00:09.476021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      "Accuracy on validation dataset: 0.8571429"
     ]
    }
   ],
   "source": [
    "#Retraining the best model (#4) using the training data to ensure accuracy\n",
    "cc_model = ksvm(as.matrix(cc_train[,1:10]),\n",
    "                as.factor(cc_train[,11]),\n",
    "                type = \"C-svc\",kernel = \"vanilladot\",\n",
    "                C = c_values[which.max(TVT_accuracy)],\n",
    "                     scaled=TRUE)\n",
    "\n",
    "#Model's prediction on test dataset\n",
    "valid_pred = predict(ccmodel,cc_validation[,1:10])\n",
    "    \n",
    "#Calculating model's prediction accuracy`for test set\n",
    "cat(\"Accuracy on validation dataset:\", sum(valid_pred == cc_validation$R1) / nrow(cc_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb6c466d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T14:00:09.544363Z",
     "iopub.status.busy": "2022-07-08T14:00:09.542734Z",
     "iopub.status.idle": "2022-07-08T14:00:09.582843Z",
     "shell.execute_reply": "2022-07-08T14:00:09.581099Z"
    },
    "papermill": {
     "duration": 0.052857,
     "end_time": "2022-07-08T14:00:09.585246",
     "exception": false,
     "start_time": "2022-07-08T14:00:09.532389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      "Accuracy on test dataset: 0.9090909"
     ]
    }
   ],
   "source": [
    "#Finally we'll run our model on the test dataset to ensure that we maintain a similar level of accuracy as the training/validation sets\n",
    "cc_model = ksvm(as.matrix(cc_train[,1:10]),\n",
    "                as.factor(cc_train[,11]),\n",
    "                type = \"C-svc\",kernel = \"vanilladot\",\n",
    "                C = c_values[which.max(TVT_accuracy)],\n",
    "                     scaled=TRUE)\n",
    "\n",
    "#Model's prediction on test dataset\n",
    "test_pred = predict(ccmodel,cc_test[,1:10])\n",
    "    \n",
    "#Calculating model's prediction accuracy`for test set\n",
    "cat(\"Accuracy on test dataset:\", sum(test_pred == cc_test$R1) / nrow(cc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3109204a",
   "metadata": {
    "papermill": {
     "duration": 0.008356,
     "end_time": "2022-07-08T14:00:09.602481",
     "exception": false,
     "start_time": "2022-07-08T14:00:09.594125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see with a lower value of C, we were actually able to come up with a highly successful model with ~91% accuracy on our test dataset. Thus, I would use a kvsm model with C = 0.01 to predict the response variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 94.036826,
   "end_time": "2022-07-08T14:00:09.732142",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-08T13:58:35.695316",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
